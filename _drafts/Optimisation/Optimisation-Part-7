We looked up at birds last week, this time round we're going to look down at something much easier to miss that can give us some more inspiration. 

Ants have a simple foraging procedure. First, a bunch of foragers head off mostly randomly away from the colony in hopes of stumbling on food to bring home. On their way back they'll leave a pheremone trail behind as they head back to the colony. The amount of pheremones they leave behind corresponding roughly to the quality of what they've found. Other ants can see these trails and pick one to follow exactly and when they return they also mark the trail, strengthening it even further. Once the food is exhausted the ants will stop leaving the pheremones and the trail will slowly evaporate. It's a simple process but very efficient - as you'll know if you've ever seen anything sweet left outside for any length of time.

We could easily adapt this process to our purposes but unfortunately someone already has. It's called Ant Colony Optimisation and the process is very simple. 

Step 1.
Design a graph for the ants to walk over. The idea here is to form the graph such that any path over the graph is a possible solution to the problem. For example say we had a binary string:

[Image of binary string with simple arcs]

It's easy enough to think of the same kind of thing for other solution representations \footnote{Continuous optimisation problems are a little harder, see the exercises for that.}. 

Step 2. Initialise the pheremones
Initialise the pheremones along this graph. Typically this just means setting the pheremones so that each path has an equal amount of pheremones/is equally smelly.

Step 3.
Release the ants. We could use real ants for this but it's probably faster to simulate their simple behaviours. Our ant starts at the first node in the graph. We want the ant to prefer the stronger paths but if we only go down the strongest path then our algorithm will converge in a few iterations. A simple approach is to normalise the pheremone weights between 0 and 1 such that the pheremone values give the probability of choosing that node from the current position. We can simply repeat this process until we have a complete path for as many ants as we want.

Step 4. 
Finally, we update the pheremones. We want to make fitter solutions more desirable and we can do the same as the ants do and put more pheremones on the stronger paths. At the same time we don't want these pheremone values increasing towards infinity, computers don't tend to like that. To keep things simple, it's common just to normalise the pheremone values connecting a node to the next so that they are between 0 and 1. This also simplifies the decision making process at Step 3.

Then, goto Step 3. Repeat till you want to finish.

-

Ant colony optimisation is an elegant algorithm and most of the tradeoffs are pretty clear. If you want to favour exploration, update the weights slower, for exploitation you do the opposite. There are many more nuances to this algorithm that I'll cover one day but there's some things that are much more interesting to talk about.

## Graphs and Statistics

Ok, from the title this may not sound quite as interesting as ants solving problems but bare with me. 

The graph structure in ACO is very powerful. The above example is just a simple sequence:

In this sequence the probability of us taking any path is not dependent on the decisions we made at any earlier stage. This is pretty much how all of our metaheuristics have operated so far, the likelihood of any decision variable taking a value has not depended on any other decision variables. More formally:

that is all of the variables are independent of each other.

But is this what we really want? Cast your mind back a few posts to Part 4 and seperable and non-seperable problems. Most interesting problems are non-seperable, this means that some variables need to vary with each other to get good solutions. For example ... We can change our graph to consider that some of these variables may want to alter with each other:



This is a far more complicated graph and also a much larger search space than before. At each step we have another k possible branches, so even for a small problem we will end up with _ possible nodes. It's probably going to take a lot of time and effort to find a good solution in this space. The interesting thing here though is that ACO has managed to learn the dependencies between the different variables. ACO throws away most of this information and ends up with just one solution. But it is an interesting prospect, what would happen if rather than just searching for a single good solution, we tried to learn a model that shows us *why* it is a good solution?


Exercises:
1. Something about prior probability distributions.