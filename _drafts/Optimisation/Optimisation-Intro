TODO: Might it be better as a 10x10 set of boxes?
TODO: Explain that metaheuristics win against heuristics when the objective function can change e.g. when a minimisation problem becomes a maximisation one

This series is for people with problems. In particular people with 'optimisation' problems, the kind of problems were you want to find the best route/timetable/layout/cpu design/brewing process - actually pretty much any problem since almost any problem can be cast as find the best *something* within some constraints. In this series we will look at the tools of the trade of metaheuristics, very general algorithms that have been regularly shown to get excellent results on some of the hardest and biggest problems. They can be effortlessly parallelised, easily generalise, and are all round good guys but - 

First a few disclaimers:

1. Metaheuristics might not be the best solution to your problem. The more you know about the problem the better you can solve it. If you know your problem is convex or can be described with a linear equation and some linear constraints, you probably want to read about classical optimisation techniques. If the problem is simple enough or you are smart enough to form a very good heuristic for the problem you probably want to use that. For everything else, there's metaheuristics.
2. This is an old field but is an evolving one. It took hundreds of years for classical optimisation techniques to be fully understood. Much of the real hard mathematical groundwork is still being laid. There will be many cases where I cannot give a complete answer as to why and where some algorithm will perform well because we simply do not know. That said these algorithms have been used and are in use solving all sorts of practical problems. The intuition for many of these algorithms is much easier to grasp than they are to prove.
3. I'm still learning about this field. I'll try my best not to get anything wrong and I'll include references for anything that I think is non-obvious but if something really goes against your intuition then email me, it may be a mistake.

With that said let's get on with it.

<hr>

Imagine I handed you a scratch card with a 10x10 grid on it. The numbers 1-100 are hidden behind the cell in the grid. We make a deal that you can scratch away 5 cells and you get to take home the largest number you find in thousands of pounds/dollars/yen. How do you decide which boxes to scratch?

If we look at this problem more formally we only have a few components:

1. A problem: Find the maximum amount of money.
2. A solution representation: In this case we could represent a solution by the coordinates of the cell which has the money e.g. (x, y).
3. An evaluation function: When we scratch a cell off we find out how much it was worth. We may be able to use this information to find better cells. 
4. Some constraints: There are 10 cells in each row and column and we can only evaluate 5 cells

This is an interesting problem because it's so simple but so general with enough boxes we could represent any possible optimisation problem. Any insights we get from this problem can be applied to optimisation as a whole. 

This is a very abstract problem though so first let's look at the something with a few more constraints: the travelling salesman problem. In the traditional travelling salesman problem you need to visit a set of cities in turn whilst minimising the total travel time. Most people don't know anything about travelling between cities, so we'll replace those cities with pubs but you can imagine it as shops/restaurants/whatever. We could call it the stumbling student problem.

In a given city, you may have a set of pubs like this:



And we want to find the shortest path that visits every pub. You can start from anywhere you like and visit them in any order. Once you've got your solution you can compare with the correct answer below:



Did you get it? Get near? I found this answer by brute forcing it on my computer. In order to do so it had to consider _ different orderings. Humans tend to be very good at this and can find pretty good solutions, very quickly.

Now try this one:



I don't expect you to try that one. I'm not even going to ask my computer to try it. With _ pubs we've reached _ different combinations. Still maybe there's an especially thirsty student out there that needs to visit all of these pubs and we need to find them a good solution. As we can't try every single combination we can't be sure that we will have found the best solution \footnote{There are variants of TSP where you can know you've got the optimal solution without considering every combination but those are not particularly interesting or practical}.

We can use some of our knowledge of pubs and cities to write a *heuristic* - an algorithm that will give us an approximate solution to the problem. If you've spent much time in pubs you'll know that they often end up on the same street. The shortest path to every pub on the same street can be found by picking the next closest one. Applying this heuristic to both datasets we get these result:



Good but not perfect. One interesting issue we run into is it's sometimes the case that we need to make a temporarily worse decision to get a better overall solution. Consider this case:



Clearly this isn't ideal as we have to go miles out of our way to finish off our trip. We call this a greedy heuristic since it prioritises short term gains. If we use the first letter from each pub as a reference we can represent the current and obviously better configuration with two strings:


Plus we can now fit the problem to our framework:

1. Problem: Find the shortest overall path
2. Solution Representation: A string of references to pubs
3. Evaluation Function: The length of a given path
4. Constraints: We must visit each pub exactly once

If we look again at the current and best path we can see that there is currently only one pub out of place. To generalise this we could see if we get a better solution when putting each pub in each spot like so:

But this leads to a lot of comparisons. Looking closer it turns out that for this problem there is just two swaps that go to a better position: the swap which immediately steps the pub to the right place and the one that swaps the out of the way pub with it's neighbour.


If we take option two and swap with the neighbour then the next solution also only has two improving swaps, and then that solution only has two improving swaps. We can follow this sequence all the way to the point that we only have one improving move: the swap that leads us to the best solution.

Our algorithm can be stated as follows:
1. Start at a random pub
2. Greedily choose the next nearest pub until all pubs are selected
3. Make a new solution by swapping each pub with it's neighbour
4. If any of these solutions are better, go back to step 3

This idea, of evaluating nearby solutions and taking the best one is called *local search*. The idea is so general we can apply it to any given problem and is our first *metaheuristic*. We could apply the same idea to the scratch card problem. If I was a generous game player I might lay out the money so that the values behind each cell increases the closer you get to the maximum amount. If this were the case, local search would be a perfect algorithm.



Then again I might also be deceitful and make it so that it just looks like it's an easy problem and the real maximum amount is hidden elsewhere...



And this simple idea shatters all of our dreams of ever finding a single algorithm that can solve all problems. For any set of problems that your algorithm works well on, I can find a counter problem on which it will fail. This is a very important part of metaheuristics and leads to a foundational idea in the field. Very loosely the better an algorithm works on one problem, the worse it must work on some other. This is called the 'no free lunch theorem'. It has some caveats but it is an essential thing to keep in mind when working with metaheuristics. 

This doesn't mean that it's not worth pursuing this problem \footnote{At some point I will do a series of posts on the fascinating work that is going into working around the NFL theorem and finding an approach that can generalise more widely}. The many hours that have been spent developing different metaheuristics has given us a set of algorithmic tools that can be applied to a range of problems. When used well, and when well aware of their limits, these tools can be very effective when solving very hard problems. In this series I want to introduce some tools and perspectives that I've found helpful when unpicking problems of this sort. 

Whilst doing so, I hope to lay a solid foundation that can help when reading further into this area and that we can build on with more advanced topics from the cutting edge of research in metaheuristics. To do so we're going to need to look at a bunch of different algorithms and extract the key ideas from each. When we look at this algorithms it's essential to keep in mind this core idea of the 'no free lunch theorem' and always be asking 'Why does this work?' and 'Where does it fail?'. Eventually we will look at this theorem in much more detail, but first we need to introduce some key concepts and terminology which you can find right here.

Since these are mental tools rather than physical things you'll need to build them for yourself. At the end of each of these posts will be some exercises to stretch your brain a little:

Exercise
The proposed local search algorithm is far from perfect. I want you to think about how you could make it better. First answer these questions with the assumption that most pubs can be found on only a small number of streets and then try without:

1. Think of a layout of pubs that would cause the greedy + local search algorithm to find a less than optimal solution. What is the worst configuration you can find? Why?
2. The local search algorithm can only work from the greedy searches starting point. Can you think of a better method of starting?
3. Both of the local search suggestions are very simple. How else could perform a local search? How about the greedy search?