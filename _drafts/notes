If you are familiar with it this will sound similar to the issues when managing a cloud computing environment and in many ways it is very similar. In cloud computing the challenge is similar, people pay you to be able to provide a certain amount of computing resource whenever you need it. So for example if you need a server that has 16 processors in it, Amazon will happily rent you one from one of their datacentres. With cloud computing we don't generally have to worry about where in the datacentre we place the network functions because we are just selling resources. However when we're placing VNFs we are not usually selling resources but selling a certain quality of service. So instead of buying a server your buying a guarantee that the service you are providing will have low latency, high throughput and 99.99999% uptime. This moves the hard decision of choosing how much resources are needed from the consumer to the service provider. Now to make these decisions at a huge scale we need to move this intelligent decision making from humans to computers. And the first step to doing this, in my mind at least, is to model it and to really understand how the problem fits together.

## Decision Space
A key property of the decision space is whether the variables in a problem are separable or non-separable. In a separable problem variables can be considered individually whereas in a non-separable problem there is some interaction between the different parts.

Going back to our 10x10 grid of boxes we could imagine a case where the prizes are allocated sequentially. With this setup we can see that any movement to the right *or* down will lead to an improvement, right down to the point where we reach the best value at (10, 10). If we wanted to we could solve this problem in two steps, first consider just the x component and then just the y, hence the problem is separable.

// TODO: Need a sensible equation for the value

On the other hand if we decide the value of the boxes based on the difference between the x and y components \footnote{e.g. f([x,y]) = |x - y|} then this problem is non-separable. If we consider just the x component e.g. search from (1, 1) to (10, 1) we would be misled into thinking that increasing the x value leads to worse solutions, likewise the same would occur if we considered only the y component. The only way to solve this problem is to consider both variables in tandem. It's worth pointing out that some problems can be partially separable or may be separable only over part of the decision space. If you are able to identify a separable component in your problem, this is a very useful property that you can exploit.

    - Decision space has many dimensions and it is often difficult to understand how they work.
    - To get around this many optimisation algorithms often use metaphors as names such as 'Ant Colony Optimisation', 'Artificial Immune System' and 'Simulated Annealing'. These can be very useful when your trying to get your head around what exactly they are doing. Be careful though not to get too stuck into the metaphor. It's very easy to separate these algorithms in your head as the metaphors are so different but ultimately they are all working in the same problem space. In this series we will look at different ways you can translate the algorithms actions into a unified problem space so you can pick and mix yuor favourite parts from each. In academia these will often be called 'hybrid algorithms' but to me it just seems like good practice. Just be sure to test your results against more established techniques and think carefully about the reasons behind the results.
        - Many of these algorithms have particular quirks/naming structures. For the most part you can ignore these details. The important part is to have a good general idea about different approaches that might fit your problem so you have a starting point for further research. 

For more complex problems with many more variables it's much harder to visualise the objective space in this way but the same properties still keep emerging. One way of thinking about complex problems is in terms of the *neighbours*. A neighbouring solution is usually defined as a solution that is one step away from some other solution and is determined partly by the choice of the solution representation.

There are a few factors we can consider when deciding when to use an algorithm:
1. The first is whether the algorithm re-evaluates solutions in the decision space. Of these Tabu search is the only approach that considers this explicity but at the cost of maintaining some memory about previously visited solutions. This isn't necessarily that important. As the number of variables you are consider increases, the decision space oftens grows exponentially. To some extent this negates issues of reevaluating solutions.

2. A more important point is how well the algorithm uses the information it has already discovered. Almost all metaheuristic algorithms assume there is some kind of information that can be revealed by using the previous solutions in some way. Random restart is fairly weak in this regard as after each run it approaches the problem with a clean slate. However it is easy to think of a problem were this could be the best we could do. In practice though if you come across a problem where random restart is the best that can be done almost any metaheuristic will perform poorly.

3. The main factor to consider when deciding what algorithm to use is how well the algorithm suits the problem and the problem specific knowledge that you have available. If you think the problem looks like a series of progressively rising hills, try ILS. If you have a great way 

TODO: Talk about swarm optimisation algorithms

Last post we extended our local search algorithm and in the process developed some global search algorithms. In that post we started to think about how we could use and re-use information over the course of a run. In the next few posts we are going to dive deeper into this idea.

In the last post we pointed out that some algorithms re-use information better than others. For example random restart doesn't consider previously discovered local optima after a restart whereas iterated local search starts from there and tabu search can be designed to consider all previous solutions. This seems like some kind of progress but we can take the idea further. What happens if instead of consider a single solution at a time, we considered multiple?

We could apply this algorithm to most any metaheuristic algorithm to some degree but for simplicities sake I'm going to introduce (another!) new algorithm that thinks about things a little differently.

## Heavy Ball
The last few algorithms we looked at showed us it was very easy to find the bottom or top of some given hill but things get trickier as soon as the 

-> Genetic Algorithm / Differential Evolution? 
-> Evolution Strategies 
    - Self adaptive
    - Mutation + Crossover + Self adaptive
    - http://www.cs.bham.ac.uk/~pxt/NIL/es.pdf
-> PSO / Swarm optimisation algorithms (Through crossover operator) 
-> A brief interlude: constraints 
    - Discuss constraints before talking about probability
-> Probability Based Approachs
    - Population based methods clustering around regions where we are expecting better solutions
    - Provide insight into metaheuristics as a probabilistic technique
    - Ant Colony Optimisation
    - Generative probabilistic based Approachs
-> No Free Lunch
-> Conclusions
    - Multiobjective Optimisation
    - Subpopulations
    - Genetic Programming
    - Further reading